
import React, { useEffect, useRef, useState } from 'react';
import { FilesetResolver, HandLandmarker } from '@mediapipe/tasks-vision';
import { TreeMode } from '../types';

interface GestureControllerProps {
  onModeChange: (mode: TreeMode) => void;
  currentMode: TreeMode;
  onHandPosition?: (x: number, y: number, detected: boolean) => void;
  onIndexFingerDetected?: (detected: boolean) => void;
}

export const GestureController: React.FC<GestureControllerProps> = ({ 
  onModeChange, 
  currentMode, 
  onHandPosition,
  onIndexFingerDetected 
}) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [handPos, setHandPos] = useState<{ x: number; y: number } | null>(null);
  const lastModeRef = useRef<TreeMode>(currentMode);
  
  // Debounce logic refs
  const openFrames = useRef(0);
  const closedFrames = useRef(0);
  const pointingFrames = useRef(0);
  const CONFIDENCE_THRESHOLD = 3; // é™ä½é˜ˆå€¼ï¼Œé€‚åº”è¾ƒä½çš„æ£€æµ‹å¸§ç‡

  // çŠ¶æ€è·Ÿè¸ª refs
  const lastGestureState = useRef<'open' | 'pointing' | 'other'>('other'); // è·Ÿè¸ªä¸Šä¸€ä¸ªæ‰‹åŠ¿çŠ¶æ€
  const hasTriggeredZoom = useRef(false); // é˜²æ­¢é‡å¤è§¦å‘

  // å¸§ç‡æ§åˆ¶
  const lastFrameTime = useRef(0);
  const targetFPS = 15; // é™ä½åˆ°15FPSï¼Œæå‡æµç•…åº¦
  const frameInterval = 1000 / targetFPS; // å¸§é—´éš”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰

  useEffect(() => {
    let handLandmarker: HandLandmarker | null = null;
    let animationFrameId: number;

    const setupMediaPipe = async () => {
      try {
        console.log("ğŸ¯ åˆå§‹åŒ– MediaPipe æ‰‹åŠ¿è¯†åˆ«...");

        // Use jsDelivr CDN (accessible in China)
        console.log("ğŸ“¦ åŠ è½½ MediaPipe Vision æ¨¡å—...");
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
        );
        console.log("âœ… MediaPipe Vision æ¨¡å—åŠ è½½æˆåŠŸ");

        // Use local model file to avoid loading from Google Storage (blocked in China)
        // Model file should be downloaded using: npm run download-model or download-model.bat/.sh
        console.log("ğŸ¤– åŠ è½½æ‰‹åŠ¿è¯†åˆ«æ¨¡å‹...");
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `/models/hand_landmarker.task`,
            delegate: "GPU"
          },
          runningMode: "VIDEO",
          numHands: 1
        });
        console.log("âœ… æ‰‹åŠ¿è¯†åˆ«æ¨¡å‹åŠ è½½æˆåŠŸ");

        startWebcam();
      } catch (error) {
        console.error("âŒ MediaPipe åˆå§‹åŒ–é”™è¯¯:", error);
        console.warn("âš ï¸ æ‰‹åŠ¿æ§åˆ¶ä¸å¯ç”¨ï¼Œåº”ç”¨ä»å¯æ­£å¸¸ä½¿ç”¨å…¶ä»–åŠŸèƒ½");
        // Don't block the app if gesture control fails
      }
    };

    const startWebcam = async () => {
      console.log("ğŸ“¹ å¯åŠ¨æ‘„åƒå¤´...");
      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        try {
          console.log("ğŸ” è¯·æ±‚æ‘„åƒå¤´æƒé™...");
          const stream = await navigator.mediaDevices.getUserMedia({
            video: { width: 320, height: 240, facingMode: "user" }
          });
          console.log("âœ… æ‘„åƒå¤´æƒé™è·å–æˆåŠŸ");

          if (videoRef.current) {
            videoRef.current.srcObject = stream;
            videoRef.current.addEventListener("loadeddata", () => {
              console.log("ğŸ¥ æ‘„åƒå¤´è§†é¢‘æµå·²å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹æ‰‹åŠ¿æ£€æµ‹");
              predictWebcam();
            });
          }
        } catch (err) {
          console.error("âŒ æ‘„åƒå¤´è®¿é—®é”™è¯¯:", err);
          if (err.name === 'NotAllowedError') {
            console.warn("âš ï¸ æ‘„åƒå¤´æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­å…è®¸æ‘„åƒå¤´è®¿é—®");
          } else if (err.name === 'NotFoundError') {
            console.warn("âš ï¸ æœªæ£€æµ‹åˆ°æ‘„åƒå¤´è®¾å¤‡");
          }
        }
      } else {
        console.warn("âš ï¸ æµè§ˆå™¨ä¸æ”¯æŒæ‘„åƒå¤´è®¿é—®");
      }
    };
    const predictWebcam = () => {
      if (!handLandmarker || !videoRef.current) return;

      const currentTimeMs = performance.now();

      // å¸§ç‡æ§åˆ¶ï¼šåªåœ¨è¾¾åˆ°ç›®æ ‡å¸§é—´éš”æ—¶è¿›è¡Œæ£€æµ‹
      if (currentTimeMs - lastFrameTime.current >= frameInterval) {
        lastFrameTime.current = currentTimeMs;

        const startTimeMs = currentTimeMs;
        if (videoRef.current.videoWidth > 0) { // Ensure video is ready
          const result = handLandmarker.detectForVideo(videoRef.current, startTimeMs);

          if (result.landmarks && result.landmarks.length > 0) {
            const landmarks = result.landmarks[0];
            detectGesture(landmarks);
          } else {
              setHandPos(null); // Clear hand position when no hand detected
              if (onHandPosition) {
                onHandPosition(0.5, 0.5, false); // No hand detected
              }
              // Reset counters if hand is lost?
              // Better to keep them to prevent flickering if hand blips out for 1 frame
              openFrames.current = Math.max(0, openFrames.current - 1);
              closedFrames.current = Math.max(0, closedFrames.current - 1);
              pointingFrames.current = Math.max(0, pointingFrames.current - 1);

              // é‡ç½®æ‰‹åŠ¿çŠ¶æ€
              lastGestureState.current = 'other';
              hasTriggeredZoom.current = false;
          }
        }
      }

      animationFrameId = requestAnimationFrame(predictWebcam);
    };

    const detectGesture = (landmarks: any[]) => {
      // 0 is Wrist
      // Tips: 8 (Index), 12 (Middle), 16 (Ring), 20 (Pinky)
      // Bases (MCP): 5, 9, 13, 17

      const wrist = landmarks[0];

      // Calculate palm center (average of wrist and finger bases)
      // Finger bases (MCP joints): 5, 9, 13, 17
      const palmCenterX = (landmarks[0].x + landmarks[5].x + landmarks[9].x + landmarks[13].x + landmarks[17].x) / 5;
      const palmCenterY = (landmarks[0].y + landmarks[5].y + landmarks[9].y + landmarks[13].y + landmarks[17].y) / 5;

      // Send hand position for camera control
      // Normalize coordinates: x and y are in [0, 1], center at (0.5, 0.5)
      setHandPos({ x: palmCenterX, y: palmCenterY });
      if (onHandPosition) {
        onHandPosition(palmCenterX, palmCenterY, true);
      }

      const fingerTips = [8, 12, 16, 20];
      const fingerBases = [5, 9, 13, 17];

      let extendedFingers = 0;

      for (let i = 0; i < 4; i++) {
        const tip = landmarks[fingerTips[i]];
        const base = landmarks[fingerBases[i]];

        // Calculate distance from wrist to tip vs wrist to base
        const distTip = Math.hypot(tip.x - wrist.x, tip.y - wrist.y);
        const distBase = Math.hypot(base.x - wrist.x, base.y - wrist.y);

        // Heuristic: If tip is significantly further from wrist than base, it's extended
        if (distTip > distBase * 1.5) { // 1.5 multiplier is a safe heuristic for extension
          extendedFingers++;
        }
      }

      // Thumb check (Tip 4 vs Base 2)
      const thumbTip = landmarks[4];
      const thumbBase = landmarks[2];
      const distThumbTip = Math.hypot(thumbTip.x - wrist.x, thumbTip.y - wrist.y);
      const distThumbBase = Math.hypot(thumbBase.x - wrist.x, thumbBase.y - wrist.y);
      if (distThumbTip > distThumbBase * 1.2) extendedFingers++;

      // æ–°çš„æ‰‹åŠ¿æ£€æµ‹é€»è¾‘
      const isPointing = extendedFingers < 5 && extendedFingers > 1; // å°‘äº5ä¸ªæŒ‡å¤´ä¸”éæ¡æ‹³
      const isOpenHand = extendedFingers >= 4; // 4ä¸ªæˆ–ä»¥ä¸ŠæŒ‡å¤´ä¸ºå¼ å¼€æ‰‹æŒ

      // è°ƒè¯•ä¿¡æ¯ï¼ˆé™ä½é¢‘ç‡ï¼‰
      if (pointingFrames.current % 10 === 0) { // æ¯10å¸§æ‰“å°ä¸€æ¬¡ï¼ˆçº¦æ¯ç§’1-2æ¬¡ï¼‰
        console.log(`ğŸ‘‹ æ‰‹åŠ¿æ£€æµ‹: ä¼¸å‡ºæ‰‹æŒ‡æ•°=${extendedFingers}, æŒ‡å‘æ‰‹åŠ¿=${isPointing}, å¼ å¼€æ‰‹æŒ=${isOpenHand}, ä¸Šä¸€ä¸ªçŠ¶æ€=${lastGestureState.current}`);
      }

      // æ£€æµ‹æ‰‹åŠ¿çŠ¶æ€å˜åŒ–
      let currentGestureState: 'open' | 'pointing' | 'other';
      if (isOpenHand) {
        currentGestureState = 'open';
      } else if (isPointing) {
        currentGestureState = 'pointing';
      } else {
        currentGestureState = 'other';
      }

      // å¤„ç†æŒ‡å‘æ‰‹åŠ¿ï¼ˆç”¨äºæ‹ç«‹å¾—æ”¾å¤§ï¼‰
      if (isPointing) {
        pointingFrames.current++;
        openFrames.current = 0;
        closedFrames.current = 0;

        // æ£€æµ‹ä»å¼ å¼€æ‰‹æŒåˆ‡æ¢åˆ°æŒ‡å‘æ‰‹åŠ¿çš„ç¬é—´
        if (lastGestureState.current === 'open' && !hasTriggeredZoom.current) {
          if (pointingFrames.current >= 2) { // çŸ­æš‚ç¡®è®¤å³å¯
            console.log(`ğŸ¯ ä»å¼ å¼€æ‰‹æŒåˆ‡æ¢åˆ°æŒ‡å‘æ‰‹åŠ¿ï¼è§¦å‘æ‹ç«‹å¾—æ”¾å¤§`);
            if (onIndexFingerDetected) {
              onIndexFingerDetected(true);
            }
            hasTriggeredZoom.current = true; // é˜²æ­¢é‡å¤è§¦å‘
          }
        }

        if (pointingFrames.current > CONFIDENCE_THRESHOLD && onIndexFingerDetected && !hasTriggeredZoom.current) {
          console.log(`ğŸ‘† æŒ‡å‘æ‰‹åŠ¿ç¡®è®¤ï¼`);
          onIndexFingerDetected(true);
        }
      } else {
        if (pointingFrames.current > CONFIDENCE_THRESHOLD) {
          console.log(`âœ‹ å–æ¶ˆæŒ‡å‘æ‰‹åŠ¿`);
        }
        pointingFrames.current = 0;
        if (onIndexFingerDetected) {
          onIndexFingerDetected(false);
        }

        // é‡ç½®è§¦å‘æ ‡å¿—ï¼Œå½“ä¸‹æ¬¡ä»å¼ å¼€åˆ‡æ¢åˆ°æŒ‡å‘æ—¶å¯ä»¥å†æ¬¡è§¦å‘
        if (currentGestureState === 'open') {
          hasTriggeredZoom.current = false;
        }
      }

      // æ›´æ–°æ‰‹åŠ¿çŠ¶æ€
      lastGestureState.current = currentGestureState;
      
      // DECISION
      if (extendedFingers >= 4 && !isPointing) {
        // OPEN HAND -> UNLEASH (CHAOS)
        openFrames.current++;
        closedFrames.current = 0;

        if (openFrames.current > CONFIDENCE_THRESHOLD) {
            if (lastModeRef.current !== TreeMode.CHAOS) {
                lastModeRef.current = TreeMode.CHAOS;
                onModeChange(TreeMode.CHAOS);
            }
        }

      } else if (extendedFingers <= 1 && !isPointing) {
        // CLOSED FIST -> RESTORE (FORMED)
        closedFrames.current++;
        openFrames.current = 0;

        if (closedFrames.current > CONFIDENCE_THRESHOLD) {
            if (lastModeRef.current !== TreeMode.FORMED) {
                lastModeRef.current = TreeMode.FORMED;
                onModeChange(TreeMode.FORMED);
            }
        }
      } else if (!isPointing) {
        // Ambiguous
        openFrames.current = 0;
        closedFrames.current = 0;
      }
    };

    setupMediaPipe();

    return () => {
      cancelAnimationFrame(animationFrameId);
      if (handLandmarker) handLandmarker.close();
    };
  }, [onModeChange]);

  // Sync ref with prop updates to prevent overriding in closure
  useEffect(() => {
    lastModeRef.current = currentMode;
  }, [currentMode]);

  return (
    <div className="absolute top-6 right-[8%] z-50 flex flex-col items-end pointer-events-none">
      
      {/* Minimal Camera Preview - Very small and discreet */}
      <div className="relative w-1 h-1 border border-[#D4AF37]/30 rounded overflow-hidden bg-black/20">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted
          className="w-full h-full object-cover transform -scale-x-100 opacity-70"
        />
        
        {/* Very discreet hand position indicator only */}
        {handPos && (
          <div 
            className="absolute w-1 h-1 bg-[#D4AF37] rounded-full"
            style={{
              left: `${(1 - handPos.x) * 100}%`,
              top: `${handPos.y * 100}%`,
              transform: 'translate(-50%, -50%)'
            }}
          />
        )}
      </div>
    </div>
  );
};
